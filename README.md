# Conversational Q&A Chatbot with LangChain, Groq, and ChromaDB 

A **conversational question-answering chatbot** built using **LangChain**, **Groq LLaMA 3.1**, **ChromaDB**, and **Hugging Face embeddings**.  
This project demonstrates how to implement **Retrieval-Augmented Generation (RAG)** to answer questions based on custom data rather than only relying on a language model‚Äôs internal knowledge.

---

##  Project Overview

This chatbot retrieves relevant information from a dataset and generates context-aware, accurate answers.  
It showcases how modern AI tools can be combined to build real-world, domain-specific AI assistants.

### Key Features
- **Web Scraping** ‚Äì Load data from web pages using `WebBaseLoader` and `BeautifulSoup`.
- **Chunking** ‚Äì Split large documents into smaller, meaningful pieces for efficient search.
- **Vector Embeddings** ‚Äì Generate embeddings using **Hugging Face Transformers**.
- **Semantic Search** ‚Äì Store and query embeddings using **ChromaDB**.
- **LLM Integration** ‚Äì Use **Groq LLaMA 3.1 (8B Instant)** for fast and context-aware responses.
- **Retrieval-Augmented Generation** ‚Äì Build a pipeline that fetches context and generates answers dynamically.

---

## üõ† Tech Stack

| Component        | Technology Used            |
|------------------|----------------------------|
| **Language**     | Python 3.10+               |
| **Framework**    | LangChain                  |
| **LLM Provider** | Groq LLaMA 3.1 (8B Instant)|
| **Vector DB**    | ChromaDB                    |
| **Embeddings**   | Hugging Face Transformers  |
| **Data Loader**  | WebBaseLoader, BeautifulSoup|
| **Environment**  | Python `venv`, `.env` file |
| **Notebook**     | Jupyter Notebook           |

---

## ‚öôÔ∏è Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/your-username/conversationalqa.git
cd conversationalqa

